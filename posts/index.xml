<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Blog on Welcome to the Octopus&#39;s Garden</title>
        <link>https://theinvisiblefoe.github.io/posts/</link>
        <description>Recent content in Blog on Welcome to the Octopus&#39;s Garden</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Fri, 26 Dec 2025 00:00:00 +0000</lastBuildDate>
        <atom:link href="https://theinvisiblefoe.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>FPUT</title>
            <link>https://theinvisiblefoe.github.io/posts/fput/</link>
            <pubDate>Fri, 26 Dec 2025 00:00:00 +0000</pubDate>
            
            <guid>https://theinvisiblefoe.github.io/posts/fput/</guid>
            <description>&lt;p&gt;Continuing the lazy turn of events, the second blog on my very &amp;ldquo;frequently updated&amp;rdquo; website, is brought to you
by another term project of mine, courtesy of my Non linear Dynamics professor and the geniuses over at Los Alamos,namely
Enrico Fermi, John Pasta, Stanislaw Ulam and Mary Tsingou. More commonly known as the FPUT problem, the methods used and the conclusions
reached in this paradox-of-the-decade have heralded the age of computational physics and a more nuanced study of CHAOS.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>Continuing the lazy turn of events, the second blog on my very &ldquo;frequently updated&rdquo; website, is brought to you
by another term project of mine, courtesy of my Non linear Dynamics professor and the geniuses over at Los Alamos,namely
Enrico Fermi, John Pasta, Stanislaw Ulam and Mary Tsingou. More commonly known as the FPUT problem, the methods used and the conclusions
reached in this paradox-of-the-decade have heralded the age of computational physics and a more nuanced study of CHAOS.</p>
<p>I had submitted a report for evaluation of the term project, which I have, similar to my previous blog, converted from LaTex to Markdown using
the All-Mighty <code>pandoc</code>. So I invite you to brew a cup of masala chai, put your glasses on, and start reading this terribly written blogpost of mine.</p>
<h1 id="history">History</h1>
<!-- raw HTML omitted -->
<p>In light of the new MANIAC(Metropolis and von Neumann Install Awful
Computers, acronym courtesy Gamow) computer, Fermi, Pasta, Ulam, and Tsingou[<a href="/posts/fput/#references">13</a>] set out to
study some physical problem using numerical simulations. They chose to
study a 1D chain of particles connected by nonlinear springs. Their goal
was to understand how energy would distribute among the normal modes of
the system over time, expecting that the nonlinearity would lead to
thermalization and equipartition of energy among the modes.
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure id="fig:authors" data-latex-placement="H">
<img src="images/fput.png" style="width:40.0%" />
<figcaption><center><center>The 4 main characters in this drama.</center></center></figcaption>
</figure>
<!-- ![actionangle](images/tori.png?width=900px "lol") -->

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


We first introduce the FPUT problem and its original expectations. Then
we will gloss over the backdrop of hamiltonian systems and ergodicity.
Finally, we will discuss the surprising results. Then we try to answer
some questions that arise from the problem. Then we try to see some
possible solutions to the problem. Finally, we connect the richness of
this problem with statistical mechanics. For this, we will use
[<a href="/posts/fput/#references">5</a>] and [<a href="/posts/fput/#references">1</a>] as our main references.</p>
<p>For the more interested reader with higher levels of motivation and reading prowess than
the nincompoop author of this blog, can also refer to the extensive review by Giovanni Gallavotti[<a href="/posts/fput/#references">6</a>]</p>
<h1 id="problem-setup">Problem Setup</h1>
<p>The FPUT problem considers a one-dimensional chain of \(N\) particles
connected by springs with linear and nonlinear restoring forces. The
Hamiltonian is as follows:
</p>
\[H = \sum_{i=1}^{N} \frac{p_i^2}{2} + \sum_{i=1}^{N} \left( \frac{1}{2} (x_{i+1} - x_i)^2 + \frac{\alpha}{3} (x_{i+1} - x_i)^3 + \frac{\beta}{4} (x_{i+1} - x_i)^4 \right)\]<p>
where \(p_i\) is the momentum of the \(i^{th}\) particle, \(x_i\) is its
position, and \(\alpha, \beta\) are the coefficients for the nonlinear
terms. The boundary conditions are fixed at both ends:
\(x_0 = x_{N+1} = 0\). The equations of motion derived from the
Hamiltonian are given by: </p>
\[\begin{align*}
        \frac{d^2 x_i}{dt^2} = (x_{i+1} - 2x_i + x_{i-1}) + \alpha \left( (x_{i+1} - x_i)^2 - (x_i - x_{i-1})^2 \right) 
        + \beta \left( (x_{i+1} - x_i)^3 - (x_i - x_{i-1})^3 \right)
\end{align*}\]<p> for \(i = 1, 2, \ldots, N\), with appropriate boundary
conditions.</p>
<h2 id="normal-modes">Normal Modes</h2>
<p>For the linear Hamiltonian \((H_0)\) , we can express the displacements in
terms of the normal mode coordinates \(Q_k\):
</p>
\[Q_k(t) = \sqrt{\frac{2}{N+1}} \sum_{j=1}^{N} x_j(t) \sin\left(\frac{\pi k j}{N+1}\right)\]<p>
where \(k = 1, 2, \ldots, N\). Each normal mode oscillates with its own
frequency \(\omega_k\):
</p>
\[\omega_k = 2 \sin\left(\frac{\pi k}{2(N+1)}\right)\]<p> The normal mode
coordinates are easily found using the Fourier expansion and plugging in
the appropriate boundary conditions. Using the normal mode coordinates,
the equations of motion for the linear system can be written as:
</p>
\[\ddot{Q}_k + \omega_k^2 Q_k = 0\]<p> with the \(k^{th}\) mode energy given
by: </p>
\[E_k = \frac{1}{2} \dot{Q}_k^2 + \frac{1}{2} \omega_k^2 Q_k^2\]<p>
Thus, we can decouple the oscillators in the linear case. No energy
exchange between modes. The original Hamiltonian with linear springs
\((H_0)\) would lead to normal modes of vibration, each with a specific
frequency. The expectation was that the addition of nonlinear
terms\((H_1)\) with perturbation, either \(\alpha\) or \(\beta\), would cause
the energy to spread out among these modes over time, leading to
thermalization and equipartition of energy.</p>
<p>For the \(\alpha\) model, the equations of motion in terms of normal modes
become:
</p>
\[\ddot{Q}_k + \omega_k^2 Q_k = -\frac{\alpha}{\sqrt{2(N+1)}} \sum_{j,l=1}^{N} C_{j l k} Q_j Q_l Q_m\]<p>
where \(C_{j l k}\) are coupling coefficients that depend on the mode
indices. Similarly, for the \(\beta\) model, we have:
</p>
\[\ddot{Q}_k + \omega_k^2 Q_k = -\frac{\beta}{2(N+1)} \sum_{j,l,m=1}^{N} D_{j l m k} Q_j Q_l Q_m Q_n\]<p>
where \(D_{j l m k}\) are the corresponding coupling coefficients.</p>
<h1 id="a-classical-mechanics-refresher">A Classical Mechanics Refresher</h1>
<p>A constant of motion is a function \(F(q_i, p_i, t)\) that remains
constant along the trajectories of the system in phase space for a given
Hamiltonian \(H(q_i, p_i, t)\). Mathematically, \(F\) is a constant of
motion if its total time derivative vanishes:
</p>
\[\frac{dF}{dt} = \frac{\partial F}{\partial t} + \{F, H\} = 0\]<p> For example, in a system
with a time-independent Lagrangian, the Hamiltonian itself is a constant
of motion, representing the total energy of the system.</p>
<h2 id="integrability">Integrability</h2>
<p>A Hamiltonian system with \(N\) degrees of freedom is said to be
integrable if it possesses \(N\) independent constants of motion. In such
systems, the equations of motion simplify significantly, and the
dynamics can be described as linear motion on an invariant tori in phase
space.</p>
<p>More formally, a Hamiltonian \(H(q_i, p_i)\) is integrable if there exists
a single-valued analytical canonical transformation to action-angle
variables \((J_i, \theta_i)\) such that the Hamiltonian depends only on
the action variables: </p>
\[H = H(J_1, J_2, \ldots, J_N)\]<p> In these
variables, the equations of motion become:
</p>
\[J_i = J_{i0}, \quad \theta_i = \omega_i(J) t + \theta_{i0}\]<p> where
\(\omega_i(J) = \frac{\partial H}{J_i}\) are the frequencies of the system. This
motion can be mapped to an invariant torus in the appropriate phase
space. The action represents radii of the tori, while the angle variable
describes the evolution on the surface of the tori.</p>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure id="fig:integrable_torus" data-latex-placement="H">
<img src="images/tori.png" style="width:40.0%" />
<figcaption><center>Invariant Torus in Phase Space for a system with 2 Degrees
of Freedom, therefore 2 Action Variables.</center></figcaption>
</figure>
<!-- ![actionangle](images/tori.png?width=900px "lol") -->

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h2 id="a-result-a-la-poincaré">A result a la Poincaré</h2>
<p>Consider perturbed Hamiltonians of the form:
</p>
\[H(J, \theta) = H_0(J) + \epsilon H_1(J, \theta)\]<p> where \(\epsilon\) is
a small parameter, \(H_0(J)\) is integrable, and the frequencies of the
unperturbed hamiltonian \(\omega_i = \frac{\partial H_0}{J_i}\) are functionally
independent.</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Poincaré Theorem</strong>
    <p>

Under these conditions, there exists no constant of motion
\(\Phi(Q_k, P_k, t)\) that is analytic in \(Q_k, P_k\) and \(\epsilon\), other
than the Hamiltonian itself.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>A nice sketch of this proof can be seen at [<a href="/posts/fput/#references">5</a>]. Basically, when
Poincaré starts with the Hamiltonian \(H = H_0 + \mu H_1\). Then he looks
for constants of the motion of the form:
</p>
\[\Phi(Q, P,\mu) = \sum_{k=0}^\infty \Phi(Q,P)\]<p> where \(Q,P\) are the
position and momentum variables and where all \(\Phi_k\) are all analytic
functions of \(Q,P\). Specifically, since \(\Phi\) is a constant of the
motion, he inserts the above expression in the Poisson Bracket equation
\(\{H,\Phi\} = 0\) and then insists that for each coefficient of each
\(\mu^k\) equal to zero. This yields \(\{H_0,\Phi_0\} = 0\), which means
\(\{H_0,\Phi_k\} = - \{H_0, \Phi_{k-1}\} ~ \forall ~ k>0\). We can solve
these equations iteratively for all \(\Phi_k\) once \(\Phi_0\), which is a
constant of motion for the integrble Hamiltonian, is specified. Poincaré
wants to analytically continue \(\Phi_0\). Then he shows that this is not
possible due to the presence of denominators which become zero for a
dense set of hypersurfaces. As a result, the only constant of motion
that can be analytically continued is the Hamiltonian itself.</p>
<h2 id="fermis-proof">Fermi&rsquo;s Proof</h2>
<p>Fermi started out his career trying to prove the ergodic hypothesis. He
proved that the class of Poincaré-type Hamiltonians are ergodic. The
proof sketch is quite straightforward. He proceeds via contradiction.
Suppose, the system is not ergodic. In consequence, at least two
distinct regions of phase space exist that are invariant under
Hamiltonian flow. Fermi now asserts that there must a surface separating
these two regions. This surface must be a constant of motion, since the
Hamiltonian flow cannot cross it. However, by Poincaré&rsquo;s result, no such
constant of motion exists for Poincaré-type Hamiltonians. Therefore, the
system must be ergodic. The problem with this proof is that Fermi
assumed that the separating surface is analytic, which is not
necessarily true. The KAM theorem shows that these surfaces are disjoint
sets that fill most of the phase space, but are not analytic.</p>
<p>Under a canonical transformation, the FPUT Hamiltonian can be expressed
as a Poincaré-type Hamiltonian. Therefore, by Fermi&rsquo;s proof, the FPUT
system is ergodic. We cannot measure ergodicity directly. However, since
Fermi&rsquo;s Proof dictates that the FPUT system is ergodic, and therefore
should follow the principle of equal a priori probabilities. This would
imply that over long times, the law of equipartition of energy should
hold. This is how the original authors wanted to verify Fermi&rsquo;s proof.</p>
<p>A more detailed explanation of this connection will be provided later in
the report.</p>
<h1 id="the-problem-with-the-problem">The Problem with The Problem</h1>
<p>However, the numerical simulations by Fermi, Pasta, Ulam and Tsingou
showed that the system did not thermalize as expected. Instead of energy
spreading out evenly among all modes, it exhibited a phenomenon known as
&quot;recurrence,&quot; where the energy returned to the initially excited mode
after some time.</p>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<img src="images/original_plot.png" style="width:35.0%" />
<figcaption><center>Original FPUT Simulation Results showing Recurrence
Phenomenon with parameters: N=32, <span
class="math inline"><em>α</em> = 0.25</span>, <span
class="math inline"><em>δ</em><em>t</em> = 1/8</span> and the initial
condition being the first normal mode excited. The total simulation is
done over 30000 time units.</center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h1 id="numerical-simulation">Numerical Simulation</h1>
<p>To verify the results of Fermi, Pasta, Ulam and Tsingou, we perform our
own numerical simulations of the FPUT system. We used both Euler and
Velocity-Verlet integration methods to solve the equations of motion.</p>
<ul>
<li>
<p>The Euler method is a simple first-order method, but it can be less
accurate and does not conserve energy well over long simulations.</p>
</li>
<li>
<p>The Velocity-Verlet method is a second-order symplectic integrator
that is more accurate and better at conserving energy in Hamiltonian
systems.</p>
<p>A nice handout on these simulations can be found at [<a href="/posts/fput/#references">7</a>]</p>
</li>
</ul>
<h2 id="euler-method">Euler Method</h2>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>


<figure data-latex-placement="H">
<img src="images/mode_energy_alpha_0.25_beta_0.0_tmax_10000.0.png"
style="width:75.0%" />
<figcaption><center>Simulation Results of the <span
class="math inline"><em>α</em></span> model using Euler Method
with parameters: N=32, <span
class="math inline"><em>α</em> = 0.25</span>, <span
class="math inline"><em>δ</em><em>t</em> = 0.1</span></center></figcaption>
</figure>

<figure data-latex-placement="H">
<img src="images/total_energy_alpha_0.25_beta_0.0_tmax_10000.0.png"
style="width:75.0%" />
<figcaption><center>We do need to verify energy conservation in our simulations.
Here is the total energy plot for the above simulation using Euler
Method.</center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h2 id="velocity-verlet">Velocity Verlet</h2>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>


<figure data-latex-placement="H">
<img src="images/modes_FPUT_verlet_alpha_0.25_TMAX_50000.0.png"
style="width:75.0%" />
<figcaption><center>Simulation Results of the <span
class="math inline"><em>α</em></span> model using Velocity-Verlet Method
with parameters: N=32, <span
class="math inline"><em>α</em> = 0.25</span>, <span
class="math inline"><em>δ</em><em>t</em> = 0.1</span></center></figcaption>
</figure>

<figure data-latex-placement="H">
<img src="images/total_energy_FPUT_verlet_alpha_0.25_TMAX_50000.0.png"
style="width:75.0%" />
<figcaption><center>We again verify the total energy conservation in the
Velocity-Verlet algorithm.</center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>We have seen that the numerical simulations do not match the theoretical
predictions by the original creators of this model. There are some
questions that need to answered, in light of this discrepancy between
the theoretical and numerical predictions.</p>
<h1 id="fermis-folly">Fermi&rsquo;s Folly</h1>
<p>The proof by Fermi has been shown to be incorrect. To see this, a
landmark theorem by Kolmogorov, Arnold and Moser is required.</p>
<div class="callout info">
  <div class="callout-content">
    <strong>KAM Theorem</strong>
    <p>

Consider a Hamiltonian system with \(N\) degrees of freedom, described by
action-angle variables \((J_i, \theta_i)\). Let the Hamiltonian be given
by: \[H(J, \theta) = H_0(J) + \epsilon H_1(J, \theta)\]

- \(H_0(J)\) is an integrable Hamiltonian and \(H_1(J, \theta)\) is a small
  perturbation. <br>

- The perturbation strength \(\epsilon\) is sufficiently small(below
   \(\epsilon_c\))<br>

- The frequencies of the unperturbed system satisfy,
  \[\det\left(\frac{\partial^2 H_0}{\partial J_i \partial J_j}\right) = \det\left(\frac{\partial \omega_k}{\partial J_j}\right) \neq 0\]<br>

Then there exists a nowhere dense set of \(H_0\) tori that are only
slightly deformed by the perturbation. Moreover, the measure of the set
of surviving tori is nearly that of the full phase space.

The completely destroyed tori of \(H_0\) is dense in the phase space, but
their total measure is small.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>The KAM theorem provides a resolution to why the FPUT system does not
thermalize for small perturbations. The surviving invariant tori still
show signatures of integrable behavior, preventing ergodicity. Fermi in
his proof assumed that the surface dividing the regions of phase space
invariant under Hamiltonian flow, is analytic. The work by Kolmogorov,
shows that these surfaces are not analytic, and are in fact
&quot;pathological monstrosities&quot;.</p>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<img src="images/KAM.png" style="width:45.0%" />
<figcaption><center>In the left is seen a set of nested tori with a cutaway
showing a Poincaré surface of section. An exploded view of this surface
of section is shown on the right. The circles represent preserved tori.
The first signs of instability are represented by the alternating
elliptic—hyperbolic pairs surrounding the origin. Moving out from the
origin, one sees intersecting invariant curves in whose neighborhood lie
trajectories which are realizations of random processes. But the true
complexity implied by this picture is that it is replicated about each
elliptic fixed point in the figure and in each replication ad infinitum.
Source [5].</span></center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h1 id="inquisitions">Inquisitions</h1>
<p>We try to answer some questions that can be asked and people have
studied.</p>
<ul>
<li>
<p>Is the FPUT system integrable or non-integrable? Note Poincaré&rsquo;s
result states that we can&rsquo;t analytically continue the constants of
motion from the unperturbed system to the perturbed system. It does
not say anything about introducing new constants of motion.</p>
</li>
<li>
<p>Does the FPUT system not thermalize at all, or does it thermalize over
very long timescales?</p>
</li>
<li>
<p>Does the FPUT system thermalize for certain initial conditions and not
for others?</p>
</li>
<li>
<p>Is the FPUT system ergodic after all?</p>
</li>
</ul>
<p>Let&rsquo;s explore these questions one by one.</p>
<h2 id="is-the-fput-system-integrable-or-non-integrable">Is the FPUT system integrable or non-integrable?</h2>
<p>People have thought for some time that the FPUT system might be
integrable after all. However, the simple answer to our question is
<strong>NO</strong>. Let us consider the \(\alpha\) model with \(N=3\) masses with
periodic boundary conditions. The Hamiltonian is given by:
</p>
\[H = \sum_{i=1}^{3} \frac{p_i^2}{2} + \sum_{i=1}^{2} \left( \frac{1}{2} (x_{i+1} - x_i)^2 + \frac{\alpha}{3} (x_{i+1} - x_i)^3 \right)\]<p>
Under a simple canonical transformation, we obtain the Hénon-Heiles
Hamiltonian, which is a well known non-integrable system, that exhibits
chaotic behavior above a certain energy threshold.</p>
<h3 id="hénon-heiles-hamiltonian">Hénon Heiles Hamiltonian</h3>
<p>The Hénon-Heiles Hamiltonian is given by:
</p>
\[H = \frac{1}{2} (p_x^2 + p_y^2) + \frac{1}{2} (x^2 + y^2) + x^2 y - \frac{1}{3} y^3\]<p>
This system was originally proposed to model the motion of a star around
a galactic center. For energies above a certain threshold, the system
exhibits chaotic behavior, with trajectories that are highly sensitive
to initial conditions.</p>
<p>As a result, we get a clue that the FPUT system might be chaotic for
higher perturbations or energies.</p>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<p> <img src="images/HenonHeiles_850.png" style="width:60.0%"
alt="image" /></p>
<figcaption><center>Poincaré surface of the Hénon-Heiles system showing chaotic
behavior at higher energies. <span class="citation"
data-cites="hhwolfram"></span></center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h2 id="does-the-fput-system-not-thermalize-at-all-or-does-it-thermalize-over-very-long-timescales">Does the FPUT system not thermalize at all, or does it thermalize over very long timescales?</h2>
<p>After some time of evolution, we see a dip in the energy of the first
mode. People had conjectured that over longer timescales, the system
might thermalize.</p>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<img src="images/mode_energy_alpha_0.25_beta_0.0_tmax_30000.0.png"
style="width:70.0%" />
<figcaption><center>Longer time simulation of the <span
class="math inline"><em>α</em></span> model using Euler Method. We see a
steady dip in energy of the first mode over successive
recurrences.</center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h3 id="super-period">Super Period</h3>
<p>Even though there an energy dip after some time, after observing a bit
longer, we see some sort of super recurrence. Almost all of the energy(
over 99%) flows back into the first mode. The super period was first
observed by Tuck and Tsingou(then Menzel) in 1972.</p>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<img src="images/tucksuper.png" style="width:50.0%" />
<figcaption><center>Original Tuck and Tsingou simulation showing super period of
recurrence. The super period is approximately 52 times the normal
recurrence period. <span class="citation"
data-cites="tucktsingou"></span></center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>We simulated the same using both Euler and Velocity Verlet algorithms.
We observe super periods in both methods, however for the euler method,
quite less than 99% of energy returns to the first mode. This problem
has been eliminated when the velocity verlet method is used.</p>
<p><div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<img src="images/mode1_energy_alpha_0.25_beta_0.0_tmax_500000.0.png"
style="width:60.0%" />
<figcaption><center>Very long time simulation of the <span
class="math inline"><em>α</em></span> model using the Euler Method. We
almost see a super period of recurrence, after which the energy returns
to the first mode almost completely. Here, we notice a problem with the
Euler method, as the total energy is not conserved well enough over such
long timescales.</center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<img src="images/Mode1_fpu_superperiod_alpha_0.25_TMAX_1000000.0.png"
style="width:100.0%" />
<figcaption><center>Very long time simulation of the <span
class="math inline"><em>α</em></span> model using the Velocity-Verlet
Method. We almost see a super period of recurrence, after which the
energy returns to the first mode almost completely. Here, we notice that
the total energy is conserved much better over such long
timescales.</center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<img src="images/Mode2_fpu_superperiod_alpha_0.25_TMAX_1000000.0.png"
style="width:100.0%" />
<figcaption><center>A super period is also observed in the second mode
energy.</center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>

</p>
<p>There have been some studies that suggest that the FPUT system might
thermalize over extremely long timescales. Similar to glassy behavior in
condensed matter systems, the FPUT system might be stuck in a metastable
state for long times before eventually reaching thermal equilibrium. KAM
theorem hints that for small perturbations, there are invariant tori
that survive. Therefore, for initial conditions lying on these tori, the
system will not thermalize. Building on this Idea F.M. Izrailev and B.V.
Chirikov proposed the <strong>stochasticity threshold</strong>, also called the
<strong>Chirikov criterion</strong>[<a href="/posts/fput/#references">4</a>]. According to this
criterion, when the perturbation strength exceeds a certain threshold,
the invariant tori break down, leading to widespread chaos in phase
space and subsequent thermalization.The original FPUT paper considers
two models, the \(\alpha\) and \(\beta\) models, with certain initial
conditions. Israilev and Chirikov showed for the \(\beta\) model,the
initial conditions lie below the stochasticity threshold for the
respective models, explaining the lack of thermalization.</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Chirikov Criterion</strong>
    <p>

Consider the \(\beta\) model with N masses. Let us assume fixed boundary
conditions. Also assume that the initial value problem is just the \(k\)th
mode excited. The stochasticity threshold for a mode number \(k\) is given
by:

\[3 \beta_s \left( \frac{\partial x}{ \partial z} \right)_m^2 \approx \begin{cases}
            \frac{3 }{k}, & \text{if  } k \ll N\\\\
            \frac{3 \pi^2}{N^2} \left(\frac{k}{N}\right)^2, & \text{if} N-k \ll N
         \end{cases}\]
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>There is region of conditions where due to the KAM theorem, the system
does not thermalize. This criterion is a property of a lot of other
systems as well. The system here exhibits <strong>Kolmogorov Stability</strong>. The
criterion shows that very high nonlinear couplings are required for
thermalization when low frequency modes are excited initially. For
higher modes and large \(N\), the threshold is much lower, and
thermalization can occur for smaller nonlinear couplings.</p>
<h1 id="resolutions">Resolutions</h1>
<h2 id="which-neighbour-is-integrable">Which neighbour is Integrable?</h2>
<p>This energy recurrence phenomenon is explained by the fact that there is
an integrable Hamiltonian in the neighbourhood of the FPUT system.(We
can map a Hamiltonian to a space where this sentence makes perfect
sense). That cannot be the linear model, since the Poincare surfaces of
the FPU are quite different from that of the linear one. In the quest
for finding a suitable candidate, two of them have been the leading
candidates,</p>
<ol>
<li>
<p>The KdV equation.</p>
</li>
<li>
<p>The toda Lattice</p>
</li>
</ol>
<h2 id="the-kdv-equation">The KdV Equation</h2>
<p>We shall look at the connection to the KdV equation in more detail. The
FPUT system can be regarded a discrete approximation to the integrable
Korteweg-de Vries (KdV) equation. Let&rsquo;s see how. We shall consider the
\(\alpha\) model for simplicity. The connection to the KdV equation is a
tiny bit technical, so bear with me. We will show that the naive
approach to the continuum limit does not work, and leads to unphysical
results. We follow the approach by [<a href="/posts/fput/#references">12</a>].</p>
<p>The FPUT equations of motion for the \(\alpha\) model with arbitrary \(m\)
and \(k\) are given by:
</p>
\[m \ddot{x}_i = k (x_{i+1} - 2x_i + x_{i-1})\left(1 + \alpha (x_{i+1} - x_{i-1}) \right)\]<p>
We approximate the spring mass system as a continuous string of length
L. Let the equilibrium positions of the masses be given by \(x_i^0 = ih\),
where \(h = L/(N+1)\) is the spacing between masses. Denote \(\rho\) is the
density of the string, then \(m = \rho h\). Let \(\kappa\) denotes the
Young&rsquo;s modulus for the string (i.e., the spring constant for a piece of
unit length) Then k = \(\kappa/h\) will be the spring constant for a piece
of length h.</p>
<p>Defining \(c = \sqrt{\kappa/\rho}\) we obtain,
</p>
\[\ddot{x}_i = c^2 \frac{(x_{i+1} - 2x_i + x_{i-1})}{h^2}\left(1 + \alpha (x_{i+1} - x_{i-1}) \right)\]<p>
Let \(u(x,t)\) be the function measuring the displacement of the string
from equilibrium at position \(x\) and time \(t\). Let us analyse for one
particular \(x=x_i\) Then,</p>
<ul>
<li>
<p>\(x_i(t) = u(x, t)\)</p>
</li>
<li>
<p>\(x_{i+1}(t) = u(x + h, t)\)</p>
</li>
<li>
<p>\(x_{i-1}(t) = u(x - h, t)\)</p>
</li>
</ul>
<p>We can see that \(\ddot{x}_i = u_{tt} (x, t)\). Using Taylor series
expansion about \(x\), we have,
</p>
\[\frac{(x_{i+1} - 2x_i + x_{i-1})}{h^2} = u_{xx}(x, t) + u_{xxxx}(x, t) \frac{h^2}{12} + O(h^4)\]<p>Similarly,
</p>
\[\alpha (x_{i+1} - x_{i-1}) = (2 \alpha h )u_x(x, t) + \frac{2 \alpha h^3}{6} u_{xxx}(x, t) + O(h^5)\]<p>We arrive at,
</p>
\[\left(\frac{1}{c^2}\right) u_{tt} - u_{xx} = \epsilon u_x u_{xx} + O(h^2)\]<p>
where \(\epsilon = 2 \alpha h\). We obtain the PDE,
</p>
\[u_{tt} = c^2(1 + \epsilon u_x )u_{xx}\]<p>One can draw parallels between this equation and the inviscid Burgers
equation, which is known to develop shocks in finite time, for generic
initial conditions. For wave like solutions, the rising part of the wave
with goes faster with \(u_x > 0\) than the fallling part with \(u_x < 0\),
leading to wave steepening and shock formation. One can see how
following the inviscid Burgers equation develops shocks over a finite
time. This happens over a characteristic time scale \(t_s\) which is found
to be much smaller than the recurrence time observed in the FPUT
simulations.</p>
<p>This is unphysical, since the FPUT system with small nonlinearity does
not exhibit such shock formation. To resolve this issue, we follow the
approach by Zabusky and Kruskal. The correct approach is to keep higher
order terms in the Taylor series expansion. Keeping terms upto order
\(h^2\), we obtain the PDE,
</p>
\[\frac{1}{c^2} u_{tt} = (1 + 2 \alpha h u_x )u_{xx} + \frac{ h^2}{12} u_{xxxx} + O(h^4)
                \tag{KZ}\]<p>The additional fourth order derivative term acts as a dispersive term,
preventing shock formation. We now differentiate w.r.t. \(x\) and define
\(w = u_x\), to obtain,
</p>
\[\frac{1}{c^2} w_{tt} = w_{xx} + \alpha h \frac{\partial^2}{\partial w \partial x} + \frac{h^2}{12} w_{xxxx} + O(h^4)\]<p>This is known as the Boussinesq equation. This admits wave like
solutions that do not form shocks, these are periodic water waves.</p>
<p>Note that for small values \(\alpha\) and \(h\), the wave like solutions
should qualitatively behave like solutions to the linear wave equation.
In general, the solutions will be superpositions of right and left
moving waves. Here, these two cases are treated differently. To be
specific, let us consider only right moving waves. We would like to look
for solutions, such that behave more and more like right moving waves
for longer and longer times as \(\alpha, h \to 0\).</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Travelling Wave ansatz</strong>
    <p>

Suppose that \(y(\xi, \tau)\) is a smooth function of two real variables
\(\xi, \tau\) such that the map \(\tau \mapsto y(\cdot, \tau)\) is uniformly
continuous from \(\mathbb{R}\) to \(L^2(\mathbb{R})\) with the sup norm.

This means that for every \(\epsilon > 0\), there exists a \(\delta > 0\)
such that for all
\[|\tau_1 - \tau_2| < \delta \implies ||y(\xi, \tau_1) - y(\xi, \tau_2)||_{L^2} < \epsilon ~~\forall ~~ \xi \in \mathbb{R}\]

Then for \(|t -t_0| < T = \delta/ (\alpha h c)\),
\(|\alpha h c (t - t_0)| < \delta\). Therefore,
\[||y(x - ct, \alpha h c t) - y(x - ct, \alpha h c t_0)||_{L^2} < \epsilon ~~\forall ~~ \xi \in \mathbb{R}\]
where \(x = \xi + ct\).
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>To interpret this physically, the function
\(u(x,t) = y(x - ct, \alpha h c t)\) uniformly approximates the right
moving wave \(u^0(x,t) = y(x - ct, \alpha h c t_0)\) over the time
interval \(|t - t_0| < T\). To restate this,
\(u(x,t) = y(x - ct, \alpha h c t)\) is approximately a right moving wave
whose shape gradually changes over time.</p>
<p>We now substitute \(w(x,t) = y(x - ct, \alpha h c t)\) into the (KZ)
equation, and divide by \(- 2 \alpha h\). Neglecting terms of order
\(O(h^4)\), we obtain the equation,
</p>
\[y_{\xi \tau} - \left(\frac{\alpha h}{2}\right) y_{\tau \tau} = -\frac{h^2}{24} y_{\xi \xi \xi \xi} - y_\xi y_{\xi \xi}\]<p>
We begin by making the substitutions, \(\xi = x - ct\) and
\(\tau = \alpha h c t\). Now, we can pass it into the continuum limit
\(\alpha, h \to 0\). We assume that \(h\) and \(\alpha\) are related such that
\(\alpha, h \to 0\) and \(h/\alpha\) tend to a positive limit. We then
define \(\delta = \lim_{h \rightarrow 0} \sqrt{\frac{h}{24 \alpha}}\).
This also means that \(\alpha h = O(h^2)\). </p>
\[\begin{align*}
                 \frac{\partial^k}{\partial x^k} = \frac{\partial^k}{\partial \xi^k} ~~;~~ \frac{\partial}{\partial t} = -c \frac{\partial \xi} + \alpha h c \frac{\partial}{\partial \tau} \\
                 \frac{\partial^2}{\partial t^2} = c^2 \frac{\partial^2}{\partial \xi^2} - 2 \alpha h c^2 \frac{\partial^2}{\partial \xi^2}{\tau}+ (\alpha h c)^2 \frac{\partial^2}{\partial \tau^2}
\end{align*}\]<p> Our wave operator reduces to
</p>
\[\frac{1}{c^2} \frac{\partial^2}{\partial t^2} - \frac{\partial^2}{\partial x^2} = - 2 \alpha h \frac{\partial^2}{\partial \xi \partial \tau}  + (\alpha h)^2 \frac{\partial^2}{\partial \tau^2}\]<p>
In this limit, we obtain the celebrated Korteweg-de Vries Equation by
taking \(v(\xi, \tau) = y_\xi(\xi, \tau)\):
</p>
\[v_\tau + v v_\xi + \delta^2 v_{\xi \xi \xi} = 0\]<p>In their seminal 1965 paper, Zabusky and Kruskal performed numerical
simulations of the KdV equation and discovered solitons, which are
stable, localized wave packets that maintain their shape while traveling
at constant speed. They then observed how solitons interfere with each
other, and found that they pass through each other without changing
shape. Using this connection to solitons, they gave a phenomenological
explanation for the recurrence phenomenon observed in the FPUT system.
We now see how these solitons arise in the KdV equation, from a small
section of the report [<a href="/posts/fput/#references">8</a>].</p>
<blockquote>
<p>Initially, the first two terms of the KdV equation dominate and the
classical overtaking phenomenon occurs; that is, \(u\) steepens in
regions where it has a negative slope. Second, after \(u\) has
steepened sufficiently, the third term becomes important and serves to
prevent the formation of a discontinuity. Instead, oscillations of
small wavelength (of order \(\delta\)) develop on the left of the front.
The amplitudes of the oscillations grow and finally each oscillation
achieves an almost steady amplitude (which increases linearly from
left to right) and has a shape almost identical to that of an
individual solitary-wave solution of the KdV equation. Finally, each
such &quot;solitary-wave pulse&quot;or &quot;soliton&quot; begins to move uniformly at
a rate (relative to the background value of u from which the pulse
rises) which is linearly proportional to its amplitude. Thus, the
solitons spread apart. Because of the periodicity, two or more
solitons eventually overlap spatially and interact nonlinearly.
Shortly after the interaction, they reappear virtually unaffected in
size or shape. In other words, solitons &quot;pass through&quot; one another
without losing their identity.</p>
<p><strong>Here we have a nonlinear physical process in which interacting
localized pulses do not scatter irreversibly.</strong></p>
</blockquote>
<div class="callout success">
  <div class="callout-content">
    <strong></strong>
    <p>

<figure data-latex-placement="H">
<img src="images/ZKsoliton.png" style="width:45.0%" />
<figcaption><center>The dashed line is the initial condition, a half cosine
wave. At an intermediate time step (B) we see the steepening of the
front of the wave. Then at longer (C) times, there is development of
oscillations of smaller wavelength near the front of the
wave.</center></figcaption>
</figure>
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>They explained the recurrence phenomenon on an FPUT system with periodic
boundary conditions. These solitons arise and interfere periodically,
leading to the recurrence of the initial state after some time. Note
that these derivation also agrees with the Chirikov criterion. The KdV
approximation is valid for small nonlinearity, which is precisely the
regime where the stochasticity threshold is high, preventing
thermalization.</p>
<h2 id="toda-lattice">Toda Lattice</h2>
<p>The N-particle Toda lattice also serves as a leading candidate as an
integrable Hamiltonian in the neighbourhood of the FPUT lattice.</p>
\[H = \frac{1}{2} \sum P_k^2 +\frac{1}{2} \left(\sum \exp\left(Q_{k} - Q_{k-1}\right) \right)\]<p>where the index \(k\) runs from \(1\) to \(N\) and we impose periodic boundary
consitions \(Q_{N+1} = Q_1\). The Toda lattice can be in a sense, the
discretized form of the KdV equation. One can show that the Toda Lattice
is completely integrable using LAX pairs.</p>
<h1 id="connection-to-statistical-mechanics">Connection to Statistical Mechanics</h1>
<p>Statistical mechanics has been one the most successful theories in
physics. It provides a microscopic explanation for macroscopic
thermodynamic phenomena, for widly different systems. Even after more
than a century after Boltzmann&rsquo;s pioneering work, the foundations of
statistical mechanics are still not quite rigourously justified. Some of
them include what the thermodynamic limit really means, whether the free
energy functionals are well defined at that limit, why do these systems
thermalize, and most importantly, the <strong>ergodic hypothesis</strong>. One might
think it would be too naive to apriori expect equipartition of energy in
a slightly perturbed system. But if we establish a connection between
ergodicity and the basic building block of statistical mechanics, the
<strong>principle of equal a priori probabilities</strong>, we can see why the FPUT
problem is so rich in its physical implications.</p>
<h2 id="ergodicity">Ergodicity</h2>
<div class="callout info">
  <div class="callout-content">
    <strong>Ergodic Hypothesis</strong>
    <p>

Over long periods of time, the time spent by a system in some region of
the phase space of microstates with the same energy is proportional to
the volume of this region.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>This is a restatement of the hypothesis that Boltzmann used to derive
the microcanonical ensemble and the law of equipartition of energy.
Let&rsquo;s see a heuristic proof of this statement.</p>
<p>Consider a system with Hamiltonian \(H(q_i, p_i)\) and total energy \(E\).
Let us discretize the phase space into small cells of volume
\(\Delta V_\Gamma\). The total time spent by the system in a cell
\(\Delta V_\Gamma\) over a long time \(T\) is given by:
</p>
\[\tau \propto \Delta V_\Gamma\]<p> Therefore, the probability of finding
the system in that cell, in our long time observation is given by:
</p>
\[P(\Delta V_\Gamma) = \frac{\tau}{T} \propto \Delta V_\Gamma\]<p> Taking
the limit \(\Delta V_\Gamma \to 0\), we obtain the probability density
function: </p>
\[dP = \rho(q_i, p_i) dV_\Gamma \propto dV_\Gamma\]<div class="callout info">
  <div class="callout-content">
    <strong>Principle of Equal Equilibrium a Priori Probabilities</strong>
    <p>

In an isolated system in equilibrium, all accessible microstates
corresponding to one macrostate are equally probable.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>This principle is the cornerstone of statistical mechanics. It allows us
to derive the microcanonical ensemble and subsequently other ensembles.
The previous definition has a certain nuance that is often overlooked.
The word accessible is very important here. The microcanonical ensemble
is,generally, defined for an isolated system with fixed total energy \(E\). Suppose
for a system which has an additional constant of motion \(\Phi(p_i, q_i)\)
. Then for a certain initial condition, both \(H(p_i, q_i)\) and
\(\Phi(p_i, q_i)\) will be conserved. Therefore, our energy hypersurface
will be further constrained to a submanifold defined by
\(\Phi(p_i, q_i) = \phi_0\). So the probability density function will be
given by:
</p>
\[dP \propto \delta(H(p_i, q_i) - E) \delta(\Phi(p_i, q_i) - \phi_0) dV_\Gamma\]<p>
We need to ensure that there are no additional constants of motion other
than the Hamiltonian itself, to obtain the microcanonical ensemble in its widely used form.
Recall that Poincaré&rsquo;s result states that for perturbed Hamiltonians of
that form, there exists no constant of motion \(\Phi(Q_k, P_k, t)\) that
is analytic in \(Q_k, P_k\) and \(\epsilon\), other than the Hamiltonian
itself. This motivated Fermi&rsquo;s proof to show that those Hamiltonians are
ergodic. The Ergodic hypothesis also helps us understand systems and
their validity in the real world. This relates time averages to ensemble
averages.
</p>
\[\overline{A} = \lim_{T \to \infty} \frac{1}{T} \int_0^T A(q(t), p(t)) dt = \langle A \rangle = \int A(q, p) \rho(q, p) dV_\Gamma\]<p>
For real systems, we can only measure time averages. The ergodic
hypothesis allows us to equate these to ensemble averages, which are
easier to compute theoretically. A proof of this hypothesis still eludes
us. There have been some system specific proofs, by von Neumann and
Birkhoff, but a general proof is still unknown.</p>
<h2 id="energy-equipartition">Energy Equipartition</h2>
<p>The principle of equal a priori probabilities leads to the law of
equipartition of energy. This is a fairly standard derivation. One can
look at any statistical mechanics textbook for details, for example
[<a href="/posts/fput/#references">9</a>]. Since equipartition of energy is a direct consequence of the
principle of equal a priori probabilities, FPUT decided to test this as
a signature of ergodicity in their system.</p>
<h1 id="remarks">Remarks</h1>
<p>The foundations of statistical mechanics are still not completely
rigourously justified. Khinchin [<a href="/posts/fput/#references">10</a>] and Ruelle [<a href="/posts/fput/#references">11</a>]
have a lot of opinions and criticisms about these foundations. The FPUT
problem is a classic example that highlights the subtleties involved in
these justifications. It launched the fields of studying solitons and
chaos theory.</p>
<p>Moreover, FPUT forever pioneered the usage of computers in physics
research.</p>
<h1 id="thats-all-folks">That&rsquo;s all folks</h1>
<p>Initially the experiment was widely referred to as the FPU problem, since Mary Tsingou was only recognised in a footnote for all the programming done
for this experiment. A very illuminating read about the problem focusing on giving the deserving credits to Mrs. Mary Tsingou Menzel is <a href="https://www.lanl.gov/media/publications/national-security-science/1220-we-thank-miss-mary-tsingou">here</a>. Unlike my previous blogpost, I shall end with a relevant quote.</p>
<pre tabindex="0"><code>                       We thank Miss Mary Tsingou
</code></pre><h1 id="danke-schön">Danke Schön</h1>
<p><em>Feel free to direct your feedback and curses to my email: <a href="mailto:iamsabarno@egmail.com">iamsabarno@gmail.com</a></em></p>
<h1 id="references">References</h1>
<p>[<a href="/posts/fput/#references">1</a>] G. P. Berman and F. M. Izrailev, The Fermi-Pasta-Ulam problem: Fifty years of progress, Chaos: An Interdisciplinary Journal of Nonlinear Science, vol. 15, no. 1, 2005. DOI: 10.1063/1.1855036.</p>
<p>[<a href="/posts/fput/#references">2</a>] Wolfram Research, Inc., Henon–Heiles System, 2002. Available at: <a href="http://mathworld.wolfram.com/Henon-HeilesSystem.html">http://mathworld.wolfram.com/Henon-HeilesSystem.html</a></p>
<p>[<a href="/posts/fput/#references">3</a>] J. L. Tuck and M. T. Menzel, The superperiod of the nonlinear weighted string (FPU) problem, Advances in Mathematics, vol. 9, no. 3, pp. 399–407, 1972. DOI: 10.1016/0001-8708(72)90024-2.</p>
<p>[<a href="/posts/fput/#references">4</a>] F. M. Izrailev and B. V. Chirikov, Statistical properties of a nonlinear string, Doklady Akademii Nauk SSSR, vol. 166, no. 1, pp. 57–59, 1966.</p>
<p>[<a href="/posts/fput/#references">5</a>] J. Ford, The Fermi-Pasta-Ulam problem: Paradox turns discovery, Physics Reports, vol. 213, no. 5, pp. 271–310, 1992. DOI: 10.1016/0370-1573(92)90116-H.</p>
<p>[<a href="/posts/fput/#references">6</a>] G. Gallavotti, The Fermi-Pasta-Ulam Problem, Lecture Notes in Physics, Springer, 2008. DOI: 10.1007/978-3-540-72995-2.</p>
<p>[<a href="/posts/fput/#references">7</a>] T. Dauxois, M. Peyrard, and S. Ruffo, The Fermi–Pasta–Ulam “numerical experiment”: history and pedagogical perspectives, European Journal of Physics, vol. 26, no. 5, pp. S3–S11, 2005. DOI: 10.1088/0143-0807/26/5/S01.</p>
<p>[<a href="/posts/fput/#references">8</a>] N. J. Zabusky and M. D. Kruskal, Interaction of solitons in a collisionless plasma and the recurrence of initial states, Physical Review Letters, vol. 15, no. 6, pp. 240–243, 1965. DOI: 10.1103/PhysRevLett.15.240.</p>
<p>[<a href="/posts/fput/#references">9</a>] K. Huang, Statistical Mechanics, 2nd ed., John Wiley &amp; Sons, 1987.</p>
<p>[<a href="/posts/fput/#references">10</a>] A. Ya. Khinchin, Mathematical Foundations of Statistical Mechanics, Dover Publications, 2013.</p>
<p>[<a href="/posts/fput/#references">11</a>] D. Ruelle, Statistical Mechanics: Rigorous Results, World Scientific Publishing, 1999.</p>
<p>[<a href="/posts/fput/#references">12</a>] R. S. Palais, The Symmetries of Solitons, arXiv:dg-ga/9708004, 1997.</p>
<p>[13] E. Fermi, J. Pasta, and S. Ulam, Studies of Nonlinear Problems, Los Alamos National Laboratory, Technical Report LA-1940, 1955.</p>
]]></content>
        </item>
        
        <item>
            <title>Equilibrium Innit</title>
            <link>https://theinvisiblefoe.github.io/posts/eqbm/</link>
            <pubDate>Fri, 04 Apr 2025 00:00:00 +0000</pubDate>
            
            <guid>https://theinvisiblefoe.github.io/posts/eqbm/</guid>
            <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;This is technically my first blog post containing actual material here. I gave a presentation for the Maths Club at my University.
The slides for which were made in LaTeX using beamer and can be found &lt;a href=&#34;https://raw.githubusercontent.com/TheInvisibleFoe/IISER_notes/main/IdentPres/slides/main.pdf&#34;&gt;here&lt;/a&gt;, on my GitHub. I just converted the latex document to markdown using Pandoc and after some minor tweaks, I have posted it here. The blog aims to demonstrate how to deal with statistically large systems(systems with a large number of degrees of freedom) and the conditions under which they might attain equilibrium. Enjoy :)&lt;/p&gt;</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>This is technically my first blog post containing actual material here. I gave a presentation for the Maths Club at my University.
The slides for which were made in LaTeX using beamer and can be found <a href="https://raw.githubusercontent.com/TheInvisibleFoe/IISER_notes/main/IdentPres/slides/main.pdf">here</a>, on my GitHub. I just converted the latex document to markdown using Pandoc and after some minor tweaks, I have posted it here. The blog aims to demonstrate how to deal with statistically large systems(systems with a large number of degrees of freedom) and the conditions under which they might attain equilibrium. Enjoy :)</p>
<h1 id="a-stochastic-description">A Stochastic Description</h1>
<p>I should probably start by giving an introduction to this stochastic stuff. Thermodynamics is a topic a lot of us are familiar with. What happens in thermodynamics?
We have something we want to study(a system) and everything else(the surroundings). In thermodynamics, we take large systems, large I mean systems with a large number of particles. A system with a
small number of particles can&rsquo;t help us glean information on macroscopic properties. We can&rsquo;t measure the velocities of say even 100 particles for a large amout of time, and conclude anything useful.
Rather, we observe large systems and infer their macroscopic properties, like Temperature and pressure. Our first stepping stone into understanding how we get from the microscopic description to the phenomenologically modeled thermodynamics, is statistical mechanics. For inferring stuff using statistical mechanics, we take some number of particles and then scale the system to reach thermodynamics.</p>
<p>Here, we are interested in a length scale between microscopic and macroscopic scales, the mesoscopic regime. Here, again the number of particles are quite large enough for particle by particle descriptions to be completely useless and the number of particles aren&rsquo;t large enough for a thermodynamic description to make sense.</p>
<p>So here, we initially lay out how we model such systems. We take particles, but instead of following the particles trajectory and accounting for all the forces exerted, say from the collisions, the particle to particle interactions, temperature fluctuations and all other phenomenon a sane person can describe. So what we do here is chalk every force that can be to some random force following some rules. So we describe these systems, using Newton&rsquo;s third alongwith a random force, often fancifully called the <em>Langevin Equation</em>. For further information you can refer to [1][3].</p>
<h3 id="stochastic-process">Stochastic Process</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Stochastic Process</strong>
    <p>


A stochastic process is a sequence of random variables where the
indexing of the variables often carries the notion of time.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>An example would be Brownian Motion, which is described by the Wiener
process.</p>
<p>\[P(\hat{W}(t+\Delta t)=x | \hat{W}(t)=x&rsquo;) = \frac{1}{\sqrt{2 \pi \Delta t}}\exp(-\frac{(x-x&rsquo;)^2}{2 \Delta t})\]</p>
<p>Let&rsquo;s see what this equation says. Suppose we have a particle moving in 1D, at a position \(x = x'\) at \(t = t_0\). Then the probability of finding the particle at some position \(x\) after some time \(\Delta t\), is described by a gaussian distribution \(N(x',\Delta t)\). This equation makes sense intuitively. The gaussian probability peaks at the mean \(x'\) and a measure of its spread is given by \(\Delta t\). Here is a small illustration,</p>
<p>








  <img src="normal_dist_std.png?width=800px" alt="Gaussian with different spreads \(\sigma\)">

</p>
<p>We can see that the width increases with increase in the standard deivation. This just means if we take a larger time step \(\Delta t\), the particle has more time to move to further and further distances, and the distribution flattens. Let&rsquo;s see what the Wiener Process looks like, before we move onto the topic of this blog.</p>
<p>








  <img src="brownian_motion.png?width=800px" alt="Brownian Motion ">

</p>
<h3 id="markov-chains">Markov Chains</h3>
<p>Most of the physical processes that we study in classical statistical
physics is modelled as Markov Chains.</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Markov Property</strong>
    <p>

Let \(\{X_n\}\) be a stochastic process. The markov
property is defined as
\[\mathbb{P}(X_{n+1}|X_n,X_{n-1},...,X_0) = \mathbb{P}(X_{n+1}|X_n)\]
Any stochastic process satisfying the Markov property is called a Markov
Chain.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>Essentially the future of the system is independent of the past given
the present state.</p>
<h3 id="continuous-time-markov-chainsctmc">Continuous Time Markov Chains(CTMC)</h3>
<p>These are markov chains with the index as time \(\{X(t)\}_t\). Let us
define a state space as the set of all values \(S\) a random variable can
assume. Then we use the notation </p>
\[P(X(t) = s) \equiv P(s;t)\]<p> We can
rewrite the markov property as
</p>
\[P(s_n;t_n|s_{n-1};t_{n-1},s_{n-2};t_{n-2},...,s_0;t_0) = P(s_n;t_n|s_{n-1};t_{n-1})\]<p>
where \(s,s_i \in S ~ \forall i\).</p>
<p>Now using the theorem of total probability we can write the Chapman
Kolmogorov equation as</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Chapman Kolmogorov Equation</strong>
    <p>
\[P(s;t|s_0;t_0) = \sum_{s' \in S} P(s;t|s';t')P(s';t'|s_0;t_0)\] where
\(t > t' > t_0\)
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>We now choose a time interval \(dt\) and rewrite the Chapman Kolmogorov
equation, dropping the explicit dependence on \(x_0,t_0\)
</p>
\[P(s;t+dt) = \sum_{s' \in S} P(s;t+dt|s';t)P(s';t)\]<p> Since this is an
infinitesimal time interval, we can write the above equation as
</p>
\[P(s;t+dt|s';t) = \delta_{ss'} +Q_{ss'}dt + o(dt)\]<p> where \(Q\) is the
transition rate matrix.</p>
<h3 id="transition-rate-matrix">Transition Rate Matrix</h3>
<p>The transition rate matrix should satisfy the following conditions</p>
<ol>
<li>
<p>\(Q_{ss'} \geq 0\) for \(s \neq s'\)</p>
</li>
<li>
<p>\(Q_{ss} = -\sum_{s' \neq s} Q_{ss'}\)</p>
</li>
</ol>
<p>The first condition ensures that the transition rate is non-negative and
the second condition essentially ensures that the probability of
transitioning from a state \(s\) to any state is 1.</p>
<p>Thus we can write </p>
\[\mathbb{P}(t+dt) = \mathbb{I} + Qdt\]<p> where
\(\mathbb{I}\) is the identity matrix.</p>
<p>We define \(k_{xx'}\) as the jump rate from state \(x'\) to \(x\). We thus
define the elements of the transition rate matrix as
</p>
\[p(x;t+dt|x';t' ) = Q_{xx'} = k_{xx'} \quad \quad x \neq x'\]<p> And the
diagonal elements are thus given as
</p>
\[Q_{xx} = -\sum_{x' \neq x} k_{xx'}\]<p>We also assume that the elements \(k_{xx'}\) do not change with time.</p>
<p>The change in probability of being in state \(x\) at time \(t\) is the
<strong>inflow</strong> of probability from all other states which is
\(k_{xx'}p(x';t)\) minus the <strong>outflow</strong> of probability \(k_{x'x}p(x;t)\).
We can now write the master equation as
</p>
\[\frac{\partial p(x;t)}{\partial t} = \sum_{x' \in S} k_{xx'}p(x';t) - k_{x'x}p(x;t)\]<p> This
becomes clearer when we define the probability current.</p>
<h3 id="master-equations">Master Equations</h3>
<p>These equations describe the time evolution of the system that are
modelled as being in the a probabilistic combination of a set of states
at any given time. These are phenomenologically modelled first order
differential equations.</p>
<p>These are used in a variety of fields in physics, and other related
fields. These are used for studying birth and death processes,
non-equilibrium statistical mechanics, chemical reactions, and a whole
lot more.<br>
The most common one that we see is the one used here is of the form
</p>
\[\frac{d \bold{p}}{ dt} = \mathbb{A}\bold{p}\]<p> where \(\mathbb{A}\) is
the matrix of connections and \(\bold{p}\) is the probability distribution
column vector.</p>
<h3 id="probability-current">Probability Current</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Probability Current</strong>
    <p>
 The probability current is defined as the flow of
probability from state \(x'\) to state \(x\). We define the probability
current as \[J_{xx'} = k_{xx'}p(x';t) - k_{x'x}p(x;t)\]

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>The master equation can now be written as
</p>
\[\frac{\partial p(x;t)}{\partial t} = \sum_{x' \in S} J_{xx'}\]<p>A bit of physics coming up ahead \(:)\)</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Microscopic Reversibility</strong>
    <p>
 If for any allowed jump
\(x \rightarrow x'\)(i.e. \(k_{xx'} > 0\)), the reverse jump
\(x' \rightarrow x\) \((k_{x'x}>0)\) is also allowed, then the system is
said to be microscopically reversible.

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h3 id="jump-networks">Jump Networks</h3>
<p>These systems are quite often represented as jump networks, where the
nodes of the graph represent the states \(x\) and the arrows(edges)
\(x' \rightarrow x\) represent the allowed jumps i.e. the jumps with
non-zero transition rates(\(k_{xx'}>0\)).</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Some Physics</strong>
    <p>
 The jump networks dealt with in physics are strongly
connected. That is, given any two states \(x\) and \(x'\), there is a
non-zero probability of transitioning from \(x\) to \(x'\) in a finite
number of steps.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>This property has some physical justification. Coupled together with
microscopic reversibility, this property ensures that the graphs aren&rsquo;t
disconnected. Disconnected graphs often lead to systems with
non-interacting components, which can be studied independently reducing
to the strongly connected graph.</p>
<p><em>Strongly connected graphs also posses a property called Irreducibility.
Irreducibility is a necessary condition for the Perron Frobenius theorem
to hold.</em></p>
<p>Here are is an example of a jump network :</p>
<p>








  <img src="jumpnetwork.png?width=800px" alt="Source : [1]">

</p>
<!-- raw HTML omitted -->
<h1 id="steady-state--equilibrium-distribution">Steady State &amp; Equilibrium Distribution</h1>
<h3 id="conditions">Conditions</h3>
<p>Steady state and equilibrium distribution are often used
interchangeably. However, they are defined quite differently. The
condition for a system to be in equilibrium is a bit more constrained
than that of a steady state.</p>
<p>The necessary condition for both to hold is that the probability of
being in a state \(x\) at time \(t\) is independent of time. Thus,
essentially our master equation equates to \(0\).
</p>
\[\frac{\partial p^{st}(x)}{\partial t} = \sum_{x' \neq x} J_{xx'} = 0\]<p>We will show that under certain conditions, the system relaxes to a
stationary state. </p>
\[\lim_{t \to \infty} p(x;t) = p^{st}(x)\]<h3 id="detailed-balance-condition">Detailed Balance Condition</h3>
<p>The independence of \(p(x)\) on time can be ensured by the following
conditions:</p>
<ol>
<li>
<p>\(\sum_{x' \neq x} J_{xx'} = 0\)</p>
</li>
<li>
<p>\(J_{xx'} = 0\) for all states \(x,x'\)</p>
</li>
</ol>
<p>Condition 1 is the condition for a steady state, while condition 2 is
the condition for equilibrium.</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Detailed Balance Condition</strong>
    <p>
 The detailed balance condition is defined as
\[k_{xx'}p^{st}(x') = k_{x'x}p^{st}(x) \quad  \forall ~x,x' \in S\]
\[J_{xx'}  =0 \quad \forall x,x' \in S\]
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>When the jump networks satisfy the detailed balance condition, the
system is said to be in equilibrium.</p>
<h1 id="perron-frobenius-theorem">Perron Frobenius Theorem</h1>
<h3 id="irreducibility">Irreducibility</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Reducibility</strong>
    <p>
 A matrix \(\mathbb{A}\) is said to be reducible when there
exists a Permutation matrix \(P\) such that \[P^TAP = \begin{pmatrix}
      \mathbb{X}& \mathbb{Y}\\
      0 & \mathbb{Z}
    \end{pmatrix}\] where \(\mathbb{X}\) and \(\mathbb{Z}\) are square
matrices.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>We can easily see that if all the elements of \(\mathbb{A}\) are positive,
then the matrix is irreducible. <em>This is a necessary condition for the
Perron Frobenius theorem to hold.</em></p>
<p>We can reframe the Irreducibility problem in terms of graphs.</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Irreducibility in terms of Graphs</strong>
    <p>


-   The graph \(G(\mathbb{A})\) of a matrix \(\mathbb{A}_{n \times n}\) is a
    directed graph on \(n\) nodes \({N_1,...,N_n}~\) in which there is a
    directed edge from \(N_i\) to \(N_j\) if and only if \(A_{ij} \neq 0\).

-   A graph \(G(\mathbb{A})\) is called strongly connected if for every
    pair of nodes \(N_i\) and \(N_j\) there is a directed path from \(N_i\) to
    \(N_j\).

-   A matrix \(\mathbb{A}\) is irreducible iff the graph of the matrix is
    strongly connected.

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>We have already assumed that the jump network is strongly connected.</p>
<h3 id="strongly-connected-graphs">Strongly Connected Graphs</h3>
<p>We can also think of Irreducibility from the point of view of the markov
chains. Two states are said to be <strong>communicating</strong> if there is a
non-zero probability of transitioning from one state to the other in a
finite number of steps. This is an equivalence relation and thus
partitions the state space into equivalence classes.<br>
The markov chain is said to be irreducible if there is only one
equivalence class, which is the state space of the Markov chain.</p>
<p>Here in our jump networks any state can be reached from any other state
in a finite number of steps. Thus our markov chain is irreducible.</p>
<p>








  <img src="scc.png?width=800px" alt="Source : Wikipedia">

</p>
<h3 id="primitive-matrices">Primitive Matrices</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Primitive Matrices</strong>
    <p>


-   A matrix \(\mathbb{A}\) is called primitive if there exists a positive
    integer \(k\) such that \(\mathbb{A}^k\) is a positive matrix (i.e. all
    elements are positive).<br>

-   A matrix \(\mathbb{A}\) is primitive if it has only one eigenvalue on
    the spectral circle.<br>

-   A non-negative irreducible matrix \(\mathbb{A}\) is primitive with
    \(r = \rho(\mathbb{A})\) iff
    \(\lim_{k \rightarrow \infty} \)\((\mathbb{A} / r)^k\) exists, in which case
    \[\lim_{k \to \infty} \left(\frac{\mathbb{A}}{r}\right)^k = \frac{p q^{T}}{q^{T} p} > 0\]
    where \(p\) and \(q\) are the Perron vectors for \(\mathbb{A}\) and
    \(\mathbb{A}^T\) respectively.<br>

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h3 id="the-perron-frobenius-theorem">The Perron Frobenius Theorem</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Perron Frobenius Theorem</strong>
    <p>
 Let \(\mathbb{A}\) be an irreducible matrix.<br>

-   There exists a positive real number \(\lambda\) such that
    \[\mathbb{A}\pi = \lambda \pi\] called the Perron-Frobenius
    eigenvalue. Moreover, the eigenvalue is the spectral radius of the
    matrix.<br>

-   The eigenspace corresponding to the Perron-Frobenius eigenvalue is
    one-dimensional, that is, the corresponding eigenvector is
    non-degenerate. <br>

-   Then there exists a unique probability vector \(\pi\) such that
    \[\mathbb{A}\pi =  \lambda \pi\] called the Perron vector. Moreover,
    the vector \(\pi\) is strictly positive.<br>

-   Furthermore, there are no non-negative eigenvectors of \(\mathbb{A}\)
    except for all positive multiples of \(\pi\).


</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h3 id="stationary-state-distribution">Stationary State Distribution</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Stationary State Dist. </strong>
    <p>
Let \(P\) be the transition probability matrix for
an irreducible Markov chain and let \(\pi\) be the perron vector for the
matrix \(P\).

-   The kth step probability matrix is given by \(P^k\) since the
    \((i,j)\)th entry of \(P^k\) is the probability of transitioning from
    state \(j\) to state \(i\) in exactly \(k\) steps.

-   The \(k\)the step distribution is given by \(p(k) = P^k p(0)\)

-   If \(\bold{P}\) is primitive and if \(e\) denotes the column of all
    ones, then the limit
    \[\lim_{k \to \infty} \bold{P}^k = \pi e^T \quad \quad \quad \text{and} \quad \quad
               \lim_{k \to \infty} p(k) = \pi\]

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p><strong>Proof</strong><br>
All stochastic matrices \(\bold{P}\) have a spectral radius
\(\rho(\bold{P}) =1\). All column sums equal to 1. Thus, \(e\) is an
eigenvector of \(\bold{P}^T\) with eigenvalue \(1\), where \(e\) is the column
vector with all ones in its entries. We also have
\(\lVert{\bold{P}}\rVert_{1} = 1\). Using the fact that
\(\rho(\star) \leq \lVert\star \rVert\) for every matrix norm(See [2]),
we get that
</p>
\[1 \leq \rho(\bold{P}) \leq \lVert\bold{P}\rVert_{1} = 1 ~~~ \Rightarrow \rho (\bold{P}) =1\]<p>We know that \(\bold{P}\) is primitive with \(\rho(\bold{P}) = 1\), we know
that </p>
\[\lim_{k \to \infty} \bold{P}^k = \frac{p q^T}{q^T p}\]<p> where \(p\)
and \(q\) are the perron vectors for \(\bold{P}\) and \(\bold{P}^T\)
respectively. The perron vector for \(\bold{P}^T\) is \(e\) and let the
perron vector for \(\bold{P}\) be \(\pi\).</p>
<p>We thus have,
</p>
\[\lim_{k \to \infty} \bold{P}^k = \frac{\pi e^T}{e^T \pi}\]<p> From the
conservation of probability we have that \(\sum_i \pi_i =1\), we have that
\(e^T\pi = \sum_i \pi_i = 1\).Thus we have
</p>
\[\lim_{k \to \infty} \bold{P}^k = \pi e^T\]<p> Now we have
</p>
\[\lim_{k \to \infty} p(k) = (\lim_{k \to \infty} \bold{P}^k) p(0)= \pi e^Tp(0)\]<p>
Again \(e^Tp(0) = \sum_i p_i(0) = 1\). This leads to
</p>
\[\lim_{k \to \infty} p(k) = \pi\]<p>Note that the stationary limit is independent of the initial
distribution \(p(0)\) here.</p>
<p>We now actually verify that \(\pi\) is indeed the stationary distribution.
Let us recast the master equation into matrix form.
</p>
\[\frac{d p(t)}{dt} = Q p(t) = \frac{1}{dt}(\bold{P}- \mathbb{I}) p(t)\]<p>
where \(Q\) is the transition rate matrix. Now we have
</p>
\[(\bold{P}- \mathbb{I})\pi = \bold{P}\pi - \pi = \pi -\pi = 0\]<p> Thus
the infinite time limit of the probability distribution is indeed the
stationary distribution. </p>
\[\Rightarrow  \frac{d \pi }{dt} = 0\]<p>Now the stationary distribution must be unique since the Perron root of
any irreducible matrix has a one dimensional eigenspace. Thus the
eigenvector must be unique due to the conservation of probability.</p>
\[ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \square\]<p>SIDE NOTE: After completing the presentation, I found a proof that
doesn&rsquo;t use Perron Frobenius theorem. However, that only proves it for a
transition rate matrix with all positive entries.[1]</p>
<div class="callout info">
  <div class="callout-content">
    <strong>Stationary State Dist.</strong>
    <p>
 for Imprimitive matrices Let \(P\) be the
transition probability matrix for an irreducible Markov chain and let
\(\pi\) be the perron vector for the matrix \(P\).

-   If \(\bold{P}\) is imprimitive and if \(e\) denotes the column of all
    ones, then the limit
    \[\lim_{k \to \infty} \frac{\mathbb{I} + \bold{P}+ ... +\bold{P}^{k-1}}{k} = \pi e^T\]
    and

    \[\lim_{k \to \infty} \frac{p(0) + p(1) + ...+p(k-1)}{k} = \pi\]
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>We use Cesaro sums to define the stationary state probability
distribution. However, we won&rsquo;t deal with it here.</p>
<h1 id="graph-theory">Graph Theory</h1>
<h3 id="preliminaries">Preliminaries</h3>
<ul>
<li>
<p>A graph is a collection of vertices and edges. The edges connect the
vertices.</p>
</li>
<li>
<p>The degree of a vertex is the number of edges connected to it.</p>
</li>
<li>
<p>A walk is a sequence of vertices connected by edges.</p>
</li>
<li>
<p>A trail is a walk with no repeated edges.</p>
</li>
<li>
<p>A cycle is a non-empty trail that starts and ends at the same
vertex.</p>
</li>
<li>
<p>A connected graph is a graph where there is a path between every
pair of vertices.</p>
</li>
</ul>
<p>








  <img src="/eqbm/drawing-stars.png" alt="Source: The Internet">

</p>
<h3 id="trees">Trees</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Trees</strong>
    <p>
 A tree is a connected graph with no cycles.


Here is one property of a tree that we plan to use later.\
A tree with \(n\) vertices has \(n-1\) edges.

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h3 id="handshaking-lemma">Handshaking Lemma</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Handshaking Lemma</strong>
    <p>
 The sum of the degrees of all the vertices of a graph
is equal to twice the number of edges.\
\[\sum_{i=1}^{n} d_i = 2|E|\] where \(d_i\) is the degree of the \(i\)th
vertex and \(|E|\) is the number of edges.


</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h3 id="an-obvious-theorem">An &quot;obvious&quot; Theorem</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>An &#34;obvious&#34; Theorem</strong>
    <p>
 A tree has at least two vertices of degree 1.


**Proof**\
Every tree has \(n-1\) edges, so the sum of the degrees of all vertices of
any tree has to be \(2(n-1)\). But if there are fewer than two vertices of
degree one, then the sum of the degrees of all vertices must be at least
\(2(n-1)+1\), which is a contradiction.

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<h1 id="equilibrium-distribution">Equilibrium Distribution</h1>
<h3 id="trees-1">Trees</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Stochastic Process</strong>
    <p>
Equilibrium dist. for trees Let the jump network be a tree. Then the
stationary state distribution is the equilibrium distribution.

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p><strong>Proof</strong><br>
We know that there exists at least \(2\) vertices with degree \(1\). Let us
label one of them as \(x\). Thus, for this vertex
\(\sum_{x' \neq x} J_{xx'} = 0\) for all states \(x'\) connected to it,
under the stationary distribution. Since this is only connected to
another vertex say \(a\), We have \(J_{xa} = 0\). We can then remove the
vertex \(x\) and the edge \(\{x,a\}\). This is still a tree, so we can do
this iteratively. We can reach a point where we have only one vertex
left. For the lone vertex, the detailed balance condition is trivially
satisfied. Thus, the equilibrium distribution is the stationary
distribution.</p>
<h3 id="cyclic-networks">Cyclic Networks</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Cyclic Network</strong>
    <p>
 A cyclic network is a graph with a cycle in it.
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<div class="callout info">
  <div class="callout-content">
    <strong>Cyclic Networks</strong>
    <p>
 For cyclic networks, the system admits an equilibrium
distribution if for any sequence states \((x_0,...,x_n)\) all different
from each other
\[k_{x_0x_1}k_{x_1x_2}...k_{x_{n-1}x_n}k_{x_nx_0} = k_{x_0x_n}k_{x_nx_{n-1}}...k_{x_1x_0}\]
</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>We can see that non-vanishing stationary currents can only survive in
loops. If we allow for all cycles the forward and back jump rates to be
equal, we can then allow for the balance of probability currents.</p>
<h3 id="note">Note</h3>
<div class="callout info">
  <div class="callout-content">
    <strong>Admission of Equilibrium Distribution</strong>
    <p>
 For cyclic networks, the system
admits an equilibrium distribution if for any sequence states
\((x_0,...,x_n)\) all different from each other
\[k_{x_0x_1}k_{x_1x_2}...k_{x_{n-1}x_n}k_{x_nx_0} = k_{x_0x_n}k_{x_nx_{n-1}}...k_{x_1x_0}\]

</p>
  </div>
</div>


<style>
   
  .callout {
    position: relative;  
    padding: 20px;
    margin: 20px 0;
    border: 4px solid;  
    border-radius: 3px;  
    font-family: Inter font, sans-serif;
    box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
  }
     
    
  .callout::before {
    content: "";
    font-family: "FontAwesome";  
    font-weight: normal;
    position: absolute;
    left: -40px;
    top: 50%;
    transform: translateY(-50%);
    font-size: 24px;
    color: inherit;
  }
   
   
  .callout.info {
    border-color:  #686868;
  }
  
  .callout.info::before {
    content: "";  
  }
  
   
  .callout.warning {
    border-color: #ff6f00;
  }
  
  .callout.warning::before {
    content: "";  
  }
  
   
  .callout.success {
    border-color: #43a047;
    border: 0px solid;  
  }
  
  .callout.success::before {
    content: "";  
  }
  
   
  .callout.error {
    border-color: #e53935;
  }
  
  .callout.error::before {
    content: "";  
  }
</style>


<p>Note that this also includes the acyclic cases as well. For all
sequences \((x_0,...,x_n)\) that is not a cycle with \(x_0\) we get
\(k_{x_0 x_n} = k_{x_n x_0} = 0\). Thus, this condition is trivially
satisfied for acyclic networks.</p>
<h1 id="thats-all-folks">That&rsquo;s all folks</h1>
<p>Somehow in all of this quite convoluted and somewhat fun maths is the physical result that we can attain equilibrium under certain conditions.
This has been the quite abrupt end of my first blog. I never know how to end, so I&rsquo;ll end on an unoriginal quote that makes absolutely zero sense in this context.</p>
<pre tabindex="0"><code>            He who has the biscuits gets to tell the story.
</code></pre><h1 id="danke-schön">Danke Schön</h1>
<p><em>Feel free to direct your feedback and curses to my email: <a href="mailto:iamsabarno@egmail.com">iamsabarno@gmail.com</a></em></p>
<h3 id="references">References</h3>
<p>[1] : Luca Peliti and Simone Pigolotti, Stochastic Thermodynamics, Princeton University Press, Princeton, NJ, 2023.</p>
<p>[2]: Carl D. Meyer, Applied Linear Algebra and Matrix Analysis, Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA, 2000.</p>
<p>[3]: Naoto Shiraishi, An Introduction to Stochastic Thermodynamics: From Basic to Advanced, Springer Nature, Fundamental Theories of Physics, vol. 212, 2023. ISBN: 978-981-19-8186-9. DOI: 10.1007/978-981-19-8186-9</p>
<p>[4]: Nico G. van Kampen, Stochastic Processes in Physics and Chemistry, 3rd ed., North-Holland, 2007. ISBN: 978-0444529657.</p>
<p>[5]: William Feller, An Introduction to Probability Theory and Its Applications, Vol. 1, 3rd ed., Wiley, 1968. ISBN: 978-0471257080.</p>
<p>[6]: Reinhard Diestel, Graph Theory, 5th ed., Springer, 2017. ISBN: 978-3662536216. Link to Online Version</p>
<p>[7]: Richard J. Trudeau, Introduction to Graph Theory, Dover Publications, 1993. ISBN: 978-0486678702.</p>
<p>[8]: Christopher Jarzynski, Equalities and Inequalities: Irreversibility and the Second Law of Thermodynamics at the Nanoscale, Annual Review of Condensed Matter Physics, vol. 2, pp. 329–351, 2011. DOI: 10.1146/annurev-conmatphys-062910-140506.</p>
]]></content>
        </item>
        
        <item>
            <title>Introduction</title>
            <link>https://theinvisiblefoe.github.io/posts/intro/</link>
            <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
            
            <guid>https://theinvisiblefoe.github.io/posts/intro/</guid>
            <description>&lt;p&gt;Hello people. I am Sabarno Saha, a physics major at the Indian Institute of Science Education and Research Kolkata.I kinda also somewhat like math.&lt;/p&gt;
&lt;p&gt;I made this website because I wanted a website. After doing that, the website lay dormant for a year because I was too lazy to even write anything for it.So now in an effort to actually do something about this website, I&amp;rsquo;ve been thinking about posting blogs about
random stuff I find cool. Also, I need to improve my writing skills because it is currently abysmal and resembles how Luke Dunphy might talk after a concussion.  I might also write some
album reviews in a different page, but I am lazy. Finally, welcome to the Octopus Garden and it&amp;rsquo;s horrendously written blogs.
This is a list of the stuff I have written till now.(I will hyperlink them later).&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>Hello people. I am Sabarno Saha, a physics major at the Indian Institute of Science Education and Research Kolkata.I kinda also somewhat like math.</p>
<p>I made this website because I wanted a website. After doing that, the website lay dormant for a year because I was too lazy to even write anything for it.So now in an effort to actually do something about this website, I&rsquo;ve been thinking about posting blogs about
random stuff I find cool. Also, I need to improve my writing skills because it is currently abysmal and resembles how Luke Dunphy might talk after a concussion.  I might also write some
album reviews in a different page, but I am lazy. Finally, welcome to the Octopus Garden and it&rsquo;s horrendously written blogs.
This is a list of the stuff I have written till now.(I will hyperlink them later).</p>
<ul>
<li>Systems attaining Equilibrium.</li>
</ul>
]]></content>
        </item>
        
    </channel>
</rss>
